{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0415135f-71fc-49ac-8d22-45a7862a8428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_transformed.shape (3, 4)\n",
      "df_dst.shape (5, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>src_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>salary</th>\n",
       "      <th>effective_start_date</th>\n",
       "      <th>effective_end_date</th>\n",
       "      <th>is_current</th>\n",
       "      <th>version_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Mohamad</td>\n",
       "      <td>Kanaan</td>\n",
       "      <td>3.4</td>\n",
       "      <td>01/04/2026 15:25:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Maurice</td>\n",
       "      <td>Kanaan</td>\n",
       "      <td>8.7</td>\n",
       "      <td>01/04/2026 15:25:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Amani</td>\n",
       "      <td>Melhem</td>\n",
       "      <td>1.6</td>\n",
       "      <td>01/04/2026 15:25:21</td>\n",
       "      <td>01/04/2026 15:25:31</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>Amani</td>\n",
       "      <td>Melhemm</td>\n",
       "      <td>1.6</td>\n",
       "      <td>01/04/2026 15:25:31</td>\n",
       "      <td>01/04/2026 15:25:41</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>Amani</td>\n",
       "      <td>Melhem</td>\n",
       "      <td>1.6</td>\n",
       "      <td>01/04/2026 15:25:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  src_id first_name last_name  salary effective_start_date  \\\n",
       "0   1      10    Mohamad    Kanaan     3.4  01/04/2026 15:25:21   \n",
       "1   2      20    Maurice    Kanaan     8.7  01/04/2026 15:25:21   \n",
       "2   3      30      Amani    Melhem     1.6  01/04/2026 15:25:21   \n",
       "3   4      30      Amani   Melhemm     1.6  01/04/2026 15:25:31   \n",
       "4   5      30      Amani    Melhem     1.6  01/04/2026 15:25:41   \n",
       "\n",
       "    effective_end_date  is_current  version_id  \n",
       "0                  NaN        True           1  \n",
       "1                  NaN        True           1  \n",
       "2  01/04/2026 15:25:31       False           1  \n",
       "3  01/04/2026 15:25:41       False           2  \n",
       "4                  NaN        True           3  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "\n",
    "df_transformed = pd.read_csv(\"tmp_df_transformed.csv\")\n",
    "df_dst = pd.read_csv(\"tmp_df_dst.csv\")\n",
    "\n",
    "print(f\"df_transformed.shape {df_transformed.shape}\")\n",
    "print(f\"df_dst.shape {df_dst.shape}\")\n",
    "\n",
    "def upsert_2(df_transformed: pd.DataFrame, df_dst: pd.DataFrame, cid: int) -> pd.DataFrame:\n",
    "    AS_OF = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "    if df_transformed is None or df_transformed.empty:\n",
    "        return (df_dst.copy() if df_dst is not None else pd.DataFrame())\n",
    "\n",
    "    src = df_transformed.copy()\n",
    "    if \"id\" not in src.columns:\n",
    "        raise ValueError(\"df_transformed must contain an 'id' column.\")\n",
    "\n",
    "    src = src.drop_duplicates(subset=[\"id\"], keep=\"last\")\n",
    "\n",
    "    dst = df_dst.copy() if df_dst is not None else pd.DataFrame()\n",
    "\n",
    "    scd_cols = [\"id\", \"src_id\", \"effective_start_date\", \"effective_end_date\", \"is_current\", \"version_id\"]\n",
    "    for c in scd_cols:\n",
    "        if c not in dst.columns:\n",
    "            dst[c] = pd.Series(dtype=\"object\")\n",
    "\n",
    "    attr_cols = [c for c in src.columns if c != \"id\"]\n",
    "    for c in attr_cols:\n",
    "        if c not in dst.columns:\n",
    "            dst[c] = pd.NA\n",
    "\n",
    "    def _alloc_ids(n: int, existing_ids: pd.Series, start: int) -> np.ndarray:\n",
    "        used = pd.to_numeric(existing_ids, errors=\"coerce\").dropna().astype(np.int64).to_numpy()\n",
    "        if used.size == 0:\n",
    "            return np.arange(start, start + n, dtype=np.int64)\n",
    "\n",
    "        mx = used.max()\n",
    "        if start > mx:\n",
    "            return np.arange(start, start + n, dtype=np.int64)\n",
    "\n",
    "        used = np.unique(used)\n",
    "        need = (mx - start + 1) + n + 8\n",
    "        mask = np.zeros(need, dtype=bool)\n",
    "        in_range = used[(used >= start) & (used < start + need)]\n",
    "        mask[in_range - start] = True\n",
    "        free = np.flatnonzero(~mask)\n",
    "        while free.size < n:\n",
    "            old = mask\n",
    "            mask = np.zeros(old.size * 2, dtype=bool)\n",
    "            mask[: old.size] = old\n",
    "            in_range = used[(used >= start) & (used < start + mask.size)]\n",
    "            mask[in_range - start] = True\n",
    "            free = np.flatnonzero(~mask)\n",
    "        return (start + free[:n]).astype(np.int64)\n",
    "\n",
    "    # ---- empty/no-current -> insert all ----\n",
    "    if dst.empty or dst[\"is_current\"].fillna(False).astype(bool).sum() == 0:\n",
    "        inserts = src.rename(columns={\"id\": \"src_id\"}).copy()\n",
    "        inserts.insert(0, \"id\", _alloc_ids(len(inserts), dst[\"id\"], cid))\n",
    "        inserts[\"effective_start_date\"] = AS_OF\n",
    "        inserts[\"effective_end_date\"] = pd.NaT\n",
    "        inserts[\"is_current\"] = True\n",
    "        inserts[\"version_id\"] = 1\n",
    "\n",
    "        cols = list(dict.fromkeys(list(dst.columns) + list(inserts.columns)))\n",
    "        return pd.concat([dst.reindex(columns=cols).iloc[0:0], inserts.reindex(columns=cols)], ignore_index=True)\n",
    "\n",
    "    # ---- current rows ----\n",
    "    cur = dst[dst[\"is_current\"].fillna(False).astype(bool)].copy()\n",
    "    cur[\"_dst_idx\"] = cur.index\n",
    "\n",
    "    # IMPORTANT: create left with src_id and WITHOUT duplicating a src_id that might already exist\n",
    "    left = src.rename(columns={\"id\": \"src_id\"}).copy()\n",
    "    left = left.loc[:, ~left.columns.duplicated()]  # defensive: drop duplicate labels if any\n",
    "\n",
    "    cur_keep = [\"src_id\", \"_dst_idx\", \"version_id\"] + attr_cols\n",
    "    cur_keep = list(dict.fromkeys(cur_keep))  # ensure uniqueness\n",
    "    cur = cur.loc[:, ~cur.columns.duplicated()]  # defensive\n",
    "\n",
    "    merged = left.merge(cur[cur_keep], on=\"src_id\", how=\"left\", suffixes=(\"\", \"_cur\"))\n",
    "\n",
    "    is_new = merged[\"_dst_idx\"].isna().to_numpy()\n",
    "\n",
    "    if attr_cols:\n",
    "        a = merged[attr_cols].to_numpy()\n",
    "        b = merged[[f\"{c}_cur\" for c in attr_cols]].to_numpy()\n",
    "        diff = (a != b) & ~(pd.isna(a) & pd.isna(b))\n",
    "        is_changed = (~is_new) & diff.any(axis=1)\n",
    "    else:\n",
    "        is_changed = np.zeros(len(merged), dtype=bool)\n",
    "\n",
    "    if is_changed.any():\n",
    "        idx_to_expire = merged.loc[is_changed, \"_dst_idx\"].astype(int).to_numpy()\n",
    "        dst.loc[idx_to_expire, \"effective_end_date\"] = AS_OF\n",
    "        dst.loc[idx_to_expire, \"is_current\"] = False\n",
    "\n",
    "    to_insert = is_new | is_changed\n",
    "    if not to_insert.any():\n",
    "        return dst\n",
    "\n",
    "    ins = merged.loc[to_insert, [\"src_id\"] + attr_cols].copy()\n",
    "\n",
    "    vmap = {}\n",
    "    if is_changed.any():\n",
    "        vmap = dict(\n",
    "            zip(\n",
    "                merged.loc[is_changed, \"src_id\"].to_numpy(),\n",
    "                (merged.loc[is_changed, \"version_id\"].astype(\"int64\") + 1).to_numpy(),\n",
    "            )\n",
    "        )\n",
    "    ins[\"version_id\"] = ins[\"src_id\"].map(vmap).fillna(1).astype(\"int64\")\n",
    "\n",
    "    ins[\"effective_start_date\"] = AS_OF\n",
    "    ins[\"effective_end_date\"] = pd.NaT\n",
    "    ins[\"is_current\"] = True\n",
    "    ins.insert(0, \"id\", _alloc_ids(len(ins), dst[\"id\"], cid))\n",
    "\n",
    "    cols = list(dict.fromkeys(list(dst.columns) + list(ins.columns)))\n",
    "    return pd.concat([dst.reindex(columns=cols), ins.reindex(columns=cols)], ignore_index=True)\n",
    "\n",
    "next_id = int(df_dst[\"id\"].max() + 1) if not df_dst[\"id\"].isna().all() else 1\n",
    "df_dst = upsert_2(df_transformed, df_dst, next_id)\n",
    "\n",
    "df_dst.to_csv(\"tmp_df_dst.csv\", index=False)\n",
    "\n",
    "df_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "842f6c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>src_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>salary</th>\n",
       "      <th>effective_start_date</th>\n",
       "      <th>effective_end_date</th>\n",
       "      <th>is_current</th>\n",
       "      <th>version_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, src_id, first_name, last_name, salary, effective_start_date, effective_end_date, is_current, version_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dst = pd.read_csv(\"tmp_df_dst.csv\")\n",
    "df_dst[df_dst[\"is_current\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8794bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d0609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_transformed.shape (1, 25)\n",
      "df_dst.shape (55845, 30)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "boolean value of NA is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdf_dst.shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_dst.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m next_id = \u001b[38;5;28mint\u001b[39m(df_dst[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m].max() + \u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df_dst[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m].isna().all() \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df_dst = \u001b[43mupsert_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_dst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m df_dst\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mupsert_2\u001b[39m\u001b[34m(df_transformed, df_dst, cid)\u001b[39m\n\u001b[32m     88\u001b[39m     a = merged[attr_cols].to_numpy()\n\u001b[32m     89\u001b[39m     b = merged[[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_cur\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m attr_cols]].to_numpy()\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     diff = (\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m) & ~(pd.isna(a) & pd.isna(b))\n\u001b[32m     91\u001b[39m     is_changed = (~is_new) & diff.any(axis=\u001b[32m1\u001b[39m)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/missing.pyx:392\u001b[39m, in \u001b[36mpandas._libs.missing.NAType.__bool__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: boolean value of NA is ambiguous"
     ]
    }
   ],
   "source": [
    "df_transformed = pd.read_parquet(\"D:/whaw/case-study-real-estate/db/transformed-data_source_LEADS.parquet\")\n",
    "df_dst = pd.read_parquet(\"D:/whaw/case-study-real-estate/db/extract-dwh_LEADS.parquet\")\n",
    "print(f\"df_transformed.shape {df_transformed.shape}\")\n",
    "print(f\"df_dst.shape {df_dst.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "def upsert_2(df_transformed: pd.DataFrame, df_dst: pd.DataFrame, cid: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    SCD Type 2 upsert (fast, vectorized).\n",
    "    - Business key in source: df_transformed['id']\n",
    "    - Stored in destination as: df_dst['src_id']\n",
    "    - Surrogate key: df_dst['id'] allocated starting from `cid` (inclusive), avoiding collisions.\n",
    "\n",
    "    SCD columns:\n",
    "      effective_start_date = current date (UTC, normalized to date)\n",
    "      effective_end_date   = NULL for current rows; set to current date when expired\n",
    "      is_current           = True/False\n",
    "      version_id              = 1..n per src_id\n",
    "\n",
    "    Change detection compares all columns in df_transformed except 'id'.\n",
    "    \"\"\"\n",
    "    print(\"df_transformed.columns\")\n",
    "    print(df_transformed.columns)\n",
    "    \n",
    "    print(\"df_dst.columns\")\n",
    "    print(df_dst.columns)\n",
    "    \n",
    "    AS_OF = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "    if df_transformed is None or df_transformed.empty:\n",
    "        return (df_dst.copy() if df_dst is not None else pd.DataFrame())\n",
    "\n",
    "    src = df_transformed.copy()\n",
    "    if \"id\" not in src.columns:\n",
    "        raise ValueError(\"df_transformed must contain an 'id' column (business key).\")\n",
    "\n",
    "    # one row per business key per batch\n",
    "    src = src.drop_duplicates(subset=[\"id\"], keep=\"last\")\n",
    "\n",
    "    dst = df_dst.copy() if df_dst is not None else pd.DataFrame()\n",
    "\n",
    "    # Ensure SCD columns exist\n",
    "    scd_cols = [\"id\", \"src_id\", \"effective_start_date\", \"effective_end_date\", \"is_current\", \"version_id\"]\n",
    "    for c in scd_cols:\n",
    "        if c not in dst.columns:\n",
    "            dst[c] = pd.Series(dtype=\"object\")\n",
    "\n",
    "    # Attribute columns = all source columns except business key\n",
    "    attr_cols = [c for c in src.columns if c != \"id\"]\n",
    "    for c in attr_cols:\n",
    "        if c not in dst.columns:\n",
    "            dst[c] = pd.NA\n",
    "\n",
    "    # Allocate surrogate ids starting at cid, skipping any already used ids\n",
    "    def _alloc_ids(n: int, existing_ids: pd.Series, start: int) -> np.ndarray:\n",
    "        used = pd.to_numeric(existing_ids, errors=\"coerce\").dropna().astype(np.int64).to_numpy()\n",
    "        if used.size == 0:\n",
    "            return np.arange(start, start + n, dtype=np.int64)\n",
    "\n",
    "        mx = used.max()\n",
    "        if start > mx:\n",
    "            return np.arange(start, start + n, dtype=np.int64)\n",
    "\n",
    "        used_set = np.unique(used)\n",
    "        need_len = (mx - start + 1) + n + 8  # slack\n",
    "        mask = np.zeros(need_len, dtype=bool)\n",
    "        in_range = used_set[(used_set >= start) & (used_set < start + need_len)]\n",
    "        mask[in_range - start] = True\n",
    "        free = np.flatnonzero(~mask)\n",
    "\n",
    "        while free.size < n:\n",
    "            old = mask\n",
    "            mask = np.zeros(old.size * 2, dtype=bool)\n",
    "            mask[: old.size] = old\n",
    "            in_range = used_set[(used_set >= start) & (used_set < start + mask.size)]\n",
    "            mask[in_range - start] = True\n",
    "            free = np.flatnonzero(~mask)\n",
    "\n",
    "        return (start + free[:n]).astype(np.int64)\n",
    "\n",
    "    # If dst has no current rows / empty: insert everything as current, end_date NULL\n",
    "    if dst.empty or dst[\"is_current\"].fillna(False).astype(bool).sum() == 0:\n",
    "        inserts = src.copy()\n",
    "        inserts[\"src_id\"] = inserts[\"id\"]\n",
    "        inserts = inserts.drop(columns=[\"id\"])\n",
    "\n",
    "        inserts.insert(0, \"id\", _alloc_ids(len(inserts), dst[\"id\"], cid))\n",
    "        inserts[\"effective_start_date\"] = AS_OF\n",
    "        inserts[\"effective_end_date\"] = pd.NaT\n",
    "        inserts[\"is_current\"] = True\n",
    "        inserts[\"version_id\"] = 1\n",
    "\n",
    "        cols = list(dict.fromkeys(list(dst.columns) + list(inserts.columns)))\n",
    "        return pd.concat([dst.reindex(columns=cols).iloc[0:0], inserts.reindex(columns=cols)], ignore_index=True)\n",
    "\n",
    "    # Work with current rows only\n",
    "    cur = dst[dst[\"is_current\"].fillna(False).astype(bool)].copy()\n",
    "    cur[\"_dst_idx\"] = cur.index\n",
    "\n",
    "    left = src.copy()\n",
    "    left[\"src_id\"] = left[\"id\"]\n",
    "\n",
    "    cur_keep = [\"src_id\", \"_dst_idx\", \"version_id\"] + attr_cols\n",
    "    merged = left.merge(cur[cur_keep], on=\"src_id\", how=\"left\", suffixes=(\"\", \"_cur\"))\n",
    "\n",
    "    is_new = merged[\"_dst_idx\"].isna().to_numpy(dtype=bool)\n",
    "\n",
    "    if attr_cols:\n",
    "        is_changed = np.zeros(len(merged), dtype=bool)\n",
    "\n",
    "        for c in attr_cols:\n",
    "            s = merged[c]\n",
    "            t = merged[f\"{c}_cur\"]\n",
    "\n",
    "            s_na = s.isna().to_numpy(dtype=bool)\n",
    "            t_na = t.isna().to_numpy(dtype=bool)\n",
    "\n",
    "            one_na = s_na ^ t_na                      # exactly one is NULL -> changed\n",
    "            both_not_na = ~(s_na | t_na)              # both present\n",
    "\n",
    "            neq = np.zeros(len(merged), dtype=bool)   # compare only where both are not NULL\n",
    "            if both_not_na.any():\n",
    "                sa = s.to_numpy(dtype=object)\n",
    "                ta = t.to_numpy(dtype=object)\n",
    "                neq[both_not_na] = sa[both_not_na] != ta[both_not_na]\n",
    "\n",
    "            is_changed |= (one_na | neq)\n",
    "\n",
    "        is_changed &= ~is_new\n",
    "    else:\n",
    "        is_changed = np.zeros(len(merged), dtype=bool)\n",
    "\n",
    "    # Expire current rows for changed keys: end_date = AS_OF (date), is_current=False\n",
    "    if is_changed.any():\n",
    "        idx_to_expire = merged.loc[is_changed, \"_dst_idx\"].astype(int).to_numpy()\n",
    "        dst.loc[idx_to_expire, \"effective_end_date\"] = AS_OF\n",
    "        dst.loc[idx_to_expire, \"is_current\"] = False\n",
    "\n",
    "    # Insert rows for new + changed keys\n",
    "    to_insert = is_new | is_changed\n",
    "    if not to_insert.any():\n",
    "        return dst\n",
    "\n",
    "    ins = merged.loc[to_insert, [\"src_id\"] + attr_cols].copy()\n",
    "\n",
    "    # version_id: 1 for new, old+1 for changed\n",
    "    v = pd.Series(1, index=ins.index, dtype=\"int64\")\n",
    "    if is_changed.any():\n",
    "        vmap = dict(\n",
    "            zip(\n",
    "                merged.loc[is_changed, \"src_id\"].to_numpy(),\n",
    "                (merged.loc[is_changed, \"version_id\"].astype(\"int64\") + 1).to_numpy(),\n",
    "            )\n",
    "        )\n",
    "        v = ins[\"src_id\"].map(vmap).fillna(1).astype(\"int64\")\n",
    "    ins[\"version_id\"] = v\n",
    "\n",
    "    ins[\"effective_start_date\"] = AS_OF\n",
    "    ins[\"effective_end_date\"] = pd.NaT\n",
    "    ins[\"is_current\"] = True\n",
    "\n",
    "    ins.insert(0, \"id\", _alloc_ids(len(ins), dst[\"id\"], cid))\n",
    "\n",
    "    cols = list(dict.fromkeys(list(dst.columns) + list(ins.columns)))\n",
    "    return pd.concat([dst.reindex(columns=cols), ins.reindex(columns=cols)], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "next_id = int(df_dst[\"id\"].max() + 1) if not df_dst[\"id\"].isna().all() else 1\n",
    "df_dst = upsert_2(df_transformed, df_dst, next_id)\n",
    "df_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8886e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
